import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO

import qc_core as qc
from export.export_so_gn_dg_word import export_so_gn_dg
from export.word_reports import ReportMeta


qc.apply_page_config()
qc.inject_global_css()

# (NEW) login + l∆∞u d·ªØ li·ªáu theo PXN
qc.require_login()

cfg = qc.render_sidebar()

sigma_cat, active_rules = qc.get_sigma_category_and_rules(
    cfg["sigma_value"], cfg["num_levels"]
)

qc.render_global_header()
qc.render_top_info_cards(cfg, sigma_cat, active_rules)

st.subheader("2Ô∏è‚É£ ‚úèÔ∏è Ghi nh·∫≠n k·∫øt qu·∫£ n·ªôi ki·ªÉm & ƒë√°nh gi√° Westgard")

cur_state = qc.get_current_analyte_state()
qc_stats = cur_state.get("qc_stats")
num_levels = cfg["num_levels"]

if qc_stats is None or qc_stats.empty:
    st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu th·ªëng k√™ QC ·ªü trang 1. Vui l√≤ng thi·∫øt l·∫≠p tr∆∞·ªõc.")
else:
    st.markdown("### üîß Ch·ªçn SD d√πng ƒë·ªÉ t√≠nh z-score")

    sd_mode = st.radio(
        "SD d√πng ƒë·ªÉ t√≠nh z-score",
        ["SD th·ª±c nghi·ªám", "SD theo CVh"],
        index=1,
        horizontal=True,
    )

    mean_dict = {}
    sd_dict = {}
    for _, row in qc_stats.iterrows():
        ctrl = row["Control"]
        mean_dict[ctrl] = row["Mean_X"]
        if sd_mode == "SD th·ª±c nghi·ªám":
            sd_dict[ctrl] = row["SD_empirical"]
        else:
            sd_dict[ctrl] = row["SD_from_CVh"]

    st.write("**Gi√° tr·ªã Mean & SD ƒëang d√πng:**")
    for ctrl in [f"Ctrl {i}" for i in range(1, num_levels + 1)]:
        m = mean_dict.get(ctrl, np.nan)
        s = sd_dict.get(ctrl, np.nan)
        if not np.isnan(m) and not np.isnan(s):
            st.write(f"- {ctrl}: Mean = `{m:.4g}`; SD = `{s:.4g}`")
        else:
            st.write(f"- {ctrl}: _ch∆∞a ƒë·ªß th√¥ng tin (thi·∫øu Mean/SD)_")

    sigma_cat_preview, active_rules_preview = qc.get_sigma_category_and_rules(
        cfg["sigma_value"], num_levels
    )
    st.markdown(
        f"**Sigma: {cfg['sigma_value']:.2f} ‚Üí nh√≥m {sigma_cat_preview}-sigma.**  \n"
        f"Quy t·∫Øc lo·∫°i b·ªè: `{', '.join(sorted(active_rules_preview))}` "
        "(ngo√†i ra lu√¥n c√≥ 1_2s l√† quy t·∫Øc c·∫£nh b√°o)."
    )

    st.markdown("### üìã Nh·∫≠p k·∫øt qu·∫£ n·ªôi ki·ªÉm h·∫±ng ng√†y")

    daily_df = cur_state.get("daily_df")
    if daily_df is None:
        data = {"Ng√†y/L·∫ßn": list(range(1, 21))}
        for ctrl in [f"Ctrl {i}" for i in range(1, num_levels + 1)]:
            data[ctrl] = [None] * 20
        daily_df = pd.DataFrame(data)


    # ƒê·ªìng b·ªô c·ªôt theo s·ªë m·ª©c QC (tr√°nh l·ªói khi ƒë·ªïi 2‚Üî3 m·ª©c: thi·∫øu/ th·ª´a c·ªôt Ctrl)
    required_cols = ["Ng√†y/L·∫ßn"] + [f"Ctrl {i}" for i in range(1, num_levels + 1)]
    # Th√™m c·ªôt c√≤n thi·∫øu
    for c in required_cols:
        if c not in daily_df.columns:
            daily_df[c] = np.nan
    # B·ªè c√°c c·ªôt Ctrl th·ª´a n·∫øu tr∆∞·ªõc ƒë√≥ nh·∫≠p 3 m·ª©c r·ªìi chuy·ªÉn v·ªÅ 2 m·ª©c
    extra_ctrl_cols = [c for c in daily_df.columns if c.startswith("Ctrl ") and c not in required_cols]
    if extra_ctrl_cols:
        daily_df = daily_df.drop(columns=extra_ctrl_cols)
    # S·∫Øp x·∫øp l·∫°i th·ª© t·ª± c·ªôt cho ƒë·∫πp
    daily_df = daily_df[required_cols]

    daily_df = st.data_editor(
        daily_df,
        num_rows="dynamic",
        use_container_width=True,
        key=f"daily_editor_{num_levels}_{cfg['test_name']}",
        column_config={
            "Ng√†y/L·∫ßn": st.column_config.NumberColumn("Ng√†y/L·∫ßn", disabled=True),
            **{
                f"Ctrl {i}": st.column_config.NumberColumn(f"Ctrl {i}")
                for i in range(1, num_levels + 1)
            },
        },
    )
    qc.update_current_analyte_state(daily_df=daily_df)

    # T√≠nh z-score
    zscore_cols = {}
    for lvl in range(1, num_levels + 1):
        ctrl = f"Ctrl {lvl}"
        mean = mean_dict.get(ctrl, np.nan)
        sd = sd_dict.get(ctrl, np.nan)
        z_col = f"z_Ctrl {lvl}"
        zscore_cols[z_col] = [
            qc.compute_zscore(v, mean, sd) if v not in (None, "") else np.nan
            for v in daily_df.get(ctrl, pd.Series([np.nan]*len(daily_df))).tolist()
        ]

    z_df = pd.DataFrame({"Ng√†y/L·∫ßn": daily_df["Ng√†y/L·∫ßn"], **zscore_cols})

    st.markdown("### üìà B·∫£ng z-score")
    st.dataframe(z_df, use_container_width=True)
    qc.update_current_analyte_state(z_df=z_df)

    if not z_df.drop(columns=["Ng√†y/L·∫ßn"]).isna().all().all():
        sigma_cat2, active_rules2, summary_df, point_df = qc.evaluate_westgard(
            z_df, num_levels=num_levels, sigma=cfg["sigma_value"]
        )

        st.markdown("### ‚úÖ ƒê√°nh gi√° theo quy t·∫Øc Westgard (theo sigma)")
        st.write(
            f"Nh√≥m sigma ƒëang √°p d·ª•ng: **{sigma_cat2}-sigma**  "
            f"‚Üí Quy t·∫Øc lo·∫°i b·ªè: `{', '.join(sorted(active_rules2))}` "
            "(ngo√†i ra lu√¥n c√≥ 1_2s l√† quy t·∫Øc c·∫£nh b√°o)."
        )

        st.dataframe(summary_df, use_container_width=True)

        # Cho ph√©p nh·∫≠p 'Ng∆∞·ªùi th·ª±c hi·ªán' theo t·ª´ng ng√†y (tr∆∞·ªõc khi xu·∫•t Word/Excel)
        st.markdown("#### ‚úçÔ∏è Ng∆∞·ªùi th·ª±c hi·ªán theo ng√†y")
        edit_people = summary_df[["Ng√†y/L·∫ßn", "Ng∆∞·ªùi th·ª±c hi·ªán"]].copy()
        edit_people = st.data_editor(
            edit_people,
            use_container_width=True,
            num_rows="fixed",
            hide_index=True,
            column_config={
                "Ng√†y/L·∫ßn": st.column_config.TextColumn("Ng√†y/L·∫ßn", disabled=True),
                "Ng∆∞·ªùi th·ª±c hi·ªán": st.column_config.TextColumn("Ng∆∞·ªùi th·ª±c hi·ªán"),
            },
            key="people_editor",
        )
        # Ghi l·∫°i v√†o summary_df
        summary_df = summary_df.drop(columns=["Ng∆∞·ªùi th·ª±c hi·ªán"]).merge(edit_people, on="Ng√†y/L·∫ßn", how="left")
        qc.update_current_analyte_state(summary_df=summary_df, point_df=point_df)

        st.info(
            "‚Ä¢ **ƒê·∫°t**: kh√¥ng vi ph·∫°m quy t·∫Øc lo·∫°i b·ªè.\n"
            "‚Ä¢ **C·∫£nh b√°o (1_2s)**: ch·ªâ vi ph·∫°m 1_2s.\n"
            "‚Ä¢ **Kh√¥ng ƒë·∫°t (Reject QC)**: vi ph·∫°m ‚â•1 quy t·∫Øc lo·∫°i b·ªè theo b·ªô quy t·∫Øc sigma.\n"
            "‚Ä¢ C·ªôt **'Vi ph·∫°m lo·∫°i b·ªè'** g·ªôp c·∫£ c·∫£nh b√°o v√† lo·∫°i b·ªè.\n"
            "‚Ä¢ **'Ng∆∞·ªùi th·ª±c hi·ªán'** ƒë·ªÉ ghi tay sau khi xu·∫•t Excel."
        )

        # Chu·∫©n b·ªã d·ªØ li·ªáu xu·∫•t s·ªï theo d√µi
        export_df = daily_df.copy()
        for col in z_df.columns:
            if col != "Ng√†y/L·∫ßn":
                export_df[col] = z_df[col]
        export_df = export_df.merge(summary_df, on="Ng√†y/L·∫ßn", how="left")

        ctrl_cols = [
            f"Ctrl {i}"
            for i in range(1, num_levels + 1)
            if f"Ctrl {i}" in export_df.columns
        ]
        z_cols_out = [
            f"z_Ctrl {i}"
            for i in range(1, num_levels + 1)
            if f"z_Ctrl {i}" in export_df.columns
        ]
        tail_cols = [
            c
            for c in ["Tr·∫°ng th√°i", "Vi ph·∫°m lo·∫°i b·ªè", "Ng∆∞·ªùi th·ª±c hi·ªán"]
            if c in export_df.columns
        ]
        ordered_cols = ["Ng√†y/L·∫ßn"] + ctrl_cols + z_cols_out + tail_cols
        export_df = export_df[ordered_cols]

        st.markdown("### üì§ Xu·∫•t Excel 'S·ªï theo d√µi KQ NK'")

        file_name = (
            f"So_theo_doi_KQ_NK_{cfg['test_name'] if cfg['test_name'] else 'Xet_nghiem'}.xlsx"
        )
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
            export_df.to_excel(writer, sheet_name="So theo doi KQ NK", index=False)
        buffer.seek(0)

        st.download_button(
            label="‚¨áÔ∏è T·∫£i file Excel 'S·ªï theo d√µi KQ NK'",
            data=buffer,
            file_name=file_name,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

        qc.update_current_analyte_state(export_df=export_df)
    else:
        st.warning(
            "Ch∆∞a c√≥ gi√° tr·ªã z-score n√†o (t·∫•t c·∫£ ƒëang tr·ªëng). H√£y nh·∫≠p k·∫øt qu·∫£ n·ªôi ki·ªÉm."
        )


# Xu·∫•t Word A4: S·ªï ghi nh·∫≠n & ƒë√°nh gi√° (2/3 m·ª©c) + bi·ªÉu ƒë·ªì Levey‚ÄìJennings (gi·ªëng app)
st.markdown("### üñ®Ô∏è Xu·∫•t Word A4 (S·ªï ghi nh·∫≠n & ƒë√°nh gi√°)")
st.caption("Th√¥ng tin bi·ªÉu m·∫´u ƒë∆∞·ª£c l·∫•y t·ª´ sidebar (kh√¥ng nh·∫≠p l·∫∑p l·∫°i).")
ten_xn = cfg.get("test_name","")
thiet_bi_pp = f'{cfg.get("device","")} / {cfg.get("method","")}'.strip(" /")
lo_qc_hd = f'L√¥: {cfg.get("qc_lot","")}  |  HSD: {cfg.get("qc_expiry","")}'.strip()
thang_nam = cfg.get("report_period","")
meta = ReportMeta(
    don_vi=cfg.get("don_vi","") or "{DON_VI}",
    phien_ban=(f'Phi√™n b·∫£n: {cfg.get("phien_ban","")}' if cfg.get("phien_ban","") else "Phi√™n b·∫£n: {PHIEN_BAN}"),
    ngay_hieu_luc=(f'Ng√†y hi·ªáu l·ª±c: {cfg.get("ngay_hieu_luc","")}' if cfg.get("ngay_hieu_luc","") else "Ng√†y hi·ªáu l·ª±c: {NGAY_HIEU_LUC}"),
    ten_xet_nghiem=ten_xn,
    thiet_bi_phuong_phap=thiet_bi_pp,
    lo_qc_han_dung=lo_qc_hd,
    thang_nam=thang_nam,
)


if st.button("üìÑ T·∫°o file Word A4 (S·ªï ghi nh·∫≠n & ƒë√°nh gi√°)"):
    try:
        z_df_state = qc.get_current_analyte_state().get("z_df")
        point_df_state = qc.get_current_analyte_state().get("point_df")

        # D√πng summary_df l√†m b·∫£ng xu·∫•t (·ªïn ƒë·ªãnh nh·∫•t)
        base_df = summary_df.copy()

        # (tu·ª≥ ch·ªçn) ƒë·∫£m b·∫£o c·ªôt "Ng∆∞·ªùi th·ª±c hi·ªán" t·ªìn t·∫°i
        if "Ng∆∞·ªùi th·ª±c hi·ªán" not in base_df.columns:
            base_df["Ng∆∞·ªùi th·ª±c hi·ªán"] = ""

        docx_buf = export_so_gn_dg(
            meta=meta,
            export_df=base_df,
            z_df=z_df_state,
            point_df=point_df_state,
            num_levels=int(cfg.get("num_levels", 3)),
        )

        st.download_button(
            label=f"‚¨áÔ∏è T·∫£i file Word A4 'S·ªï ghi nh·∫≠n & ƒë√°nh gi√° ({cfg.get('num_levels',3)} m·ª©c)'",
            data=docx_buf,
            file_name=f"So_ghi_nhan_danh_gia_{cfg.get('num_levels',3)}muc_{ten_xn or 'IQC'}.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        )

    except Exception as e:
        st.error(f"Kh√¥ng th·ªÉ xu·∫•t Word: {e}")
